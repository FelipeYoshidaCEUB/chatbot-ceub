# Chatbot Nascentia - Projeto Unificado

Chatbot RAG (Retrieval-Augmented Generation) da Nascentia com suporte para mÃºltiplos modelos de linguagem (OpenAI e HuggingFace).

## ğŸš€ CaracterÃ­sticas

- **MÃºltiplos Modelos**: Suporte para OpenAI GPT-4o-mini e HuggingFace Qwen2.5-1.5B
- **Interface Streamlit**: Interface web moderna e intuitiva
- **Processamento de PDFs**: Carrega e processa mÃºltiplos documentos PDF automaticamente
- **MemÃ³ria de Conversa**: MantÃ©m contexto da conversa durante a sessÃ£o
- **CitaÃ§Ãµes AutomÃ¡ticas**: Inclui referÃªncias Ã s fontes dos documentos
- **Ãndices FAISS Persistentes**: Salva e carrega Ã­ndices separados para cada modelo
- **Seletor de Modelo**: Escolha entre diferentes modelos na interface

## ğŸ“‹ PrÃ©-requisitos

1. **Python 3.8+**
2. **Tokens de API**:
   - Para OpenAI: `OPENAI_API_KEY` no arquivo `.env`
   - Para HuggingFace: `HUGGINGFACEHUB_API_TOKEN` no arquivo `.env`
3. **DependÃªncias**: Instalar as dependÃªncias do arquivo `requirements.txt`

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com:

```env
OPENAI_API_KEY=sk-seu_token_openai_aqui
HUGGINGFACEHUB_API_TOKEN=hf_seu_token_huggingface_aqui
```

### 3. Preparar Documentos

1. Coloque seus arquivos PDF na pasta `data/`
2. O chatbot processarÃ¡ automaticamente todos os PDFs encontrados ao carregar o modelo

### 4. Executar a AplicaÃ§Ã£o

```bash
streamlit run streamlit_app.py
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em `http://localhost:8501`

## ğŸ¤– Modelos DisponÃ­veis

### OpenAI (GPT-4o-mini)
- **Embeddings**: `text-embedding-3-small`
- **Chat**: `gpt-4o-mini`
- **Chunk Size**: 1500 caracteres
- **Chunk Overlap**: 200 caracteres

### HuggingFace (Qwen2.5-1.5B)
- **Embeddings**: `intfloat/multilingual-e5-large-instruct`
- **Chat**: `Qwen/Qwen2.5-1.5B-Instruct`
- **Chunk Size**: 400 caracteres
- **Chunk Overlap**: 50 caracteres

## ğŸ“ Estrutura de Arquivos

```
chatbot-ceub/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base_chatbot.py          # Classe base abstrata
â”‚   â”‚   â”œâ”€â”€ openai_chatbot.py        # ImplementaÃ§Ã£o OpenAI
â”‚   â”‚   â””â”€â”€ huggingface_chatbot.py   # ImplementaÃ§Ã£o HuggingFace
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py                 # ConfiguraÃ§Ãµes centralizadas
â”‚       â””â”€â”€ document_processor.py     # Processamento de documentos
â”œâ”€â”€ data/                              # DiretÃ³rio para PDFs
â”œâ”€â”€ faiss_index/                       # Ãndices FAISS persistentes
â”‚   â”œâ”€â”€ openai/                       # Ãndice para modelo OpenAI
â”‚   â””â”€â”€ huggingface/                   # Ãndice para modelo HuggingFace
â”œâ”€â”€ streamlit_app.py                   # Interface Streamlit
â”œâ”€â”€ requirements.txt                   # DependÃªncias
â”œâ”€â”€ .env                               # VariÃ¡veis de ambiente (criar)
â””â”€â”€ README.md                          # Este arquivo
```

## ğŸ’» Uso

1. **Iniciar a aplicaÃ§Ã£o**: Execute `streamlit run streamlit_app.py`
2. **Selecionar modelo**: Na barra lateral, escolha entre OpenAI ou HuggingFace
3. **Carregar modelo**: Clique em "Carregar/Recarregar Modelo"
4. **Fazer upload de documentos** (opcional): Se ainda nÃ£o houver Ã­ndice, faÃ§a upload de PDFs
5. **Conversar**: Use a aba "Chat" para fazer perguntas
6. **Visualizar chunks**: Use a aba "VisualizaÃ§Ã£o" para ver os chunks indexados

## ğŸ”„ MigraÃ§Ã£o de Ãndices Existentes

Se vocÃª jÃ¡ tinha Ã­ndices FAISS dos projetos anteriores:

- **OpenAI**: Copie os arquivos de `chatbot_openIA/faiss_index/` para `faiss_index/openai/`
- **HuggingFace**: Copie os arquivos de `chatbot_hugging/faiss_index/` para `faiss_index/huggingface/`

## ğŸ“ Notas

- Cada modelo mantÃ©m seu prÃ³prio Ã­ndice FAISS separado
- Os Ã­ndices sÃ£o criados automaticamente na primeira execuÃ§Ã£o
- Documentos podem ser adicionados via upload na interface
- O histÃ³rico de conversa Ã© mantido durante a sessÃ£o

## ğŸ‘¥ Integrantes

- Rafael Martins
- Felipe Yoshida
- Matheus Alves
- Mateus Bitar
- JosÃ© Muller
- JoÃ£o Pedro Borges

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte do Projeto Integrador III do curso de CiÃªncia de Dados e Machine Learning â€“ CEUB.

